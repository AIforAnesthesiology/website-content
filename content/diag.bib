
@article{10.1016/j.jclinane.2021.110278, 
year = {2021}, 
title = {{Constructing a prediction model for difficult intubation of obese patients based on machine learning}}, 
author = {Zhou, Cheng-Mao and Xue, Qiong and Ye, Hao-Tian and Wang, Ying and Tong, Jianhua and Ji, Mu-Huo and Yang, Jian-Jun}, 
journal = {Journal of Clinical Anesthesia}, 
issn = {0952-8180}, 
doi = {10.1016/j.jclinane.2021.110278}, 
pmid = {33857844}, 
pages = {110278}, 
volume = {72}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Journal%20of%20Clinical%20Anesthesia/Zhou-2021-Constructing%20a%20prediction%20model%20for%20difficult%20intubation%20of%20obese%20patients%20based%20on%20machine%20learning.pdf}
}
@article{10.1186/s12871-021-01343-4, 
year = {2021}, 
title = {{Development and validation of a difficult laryngoscopy prediction model using machine learning of neck circumference and thyromental height}}, 
author = {Kim, Jong Ho and Kim, Haewon and Jang, Ji Su and Hwang, Sung Mi and Lim, So Young and Lee, Jae Jun and Kwon, Young Suk}, 
journal = {BMC Anesthesiology}, 
doi = {10.1186/s12871-021-01343-4}, 
pmid = {33882838}, 
abstract = {{Predicting difficult airway is challengeable in patients with limited airway evaluation. The aim of this study is to develop and validate a model that predicts difficult laryngoscopy by machine learning of neck circumference and thyromental height as predictors that can be used even for patients with limited airway evaluation. Variables for prediction of difficulty laryngoscopy included age, sex, height, weight, body mass index, neck circumference, and thyromental distance. Difficult laryngoscopy was defined as Grade 3 and 4 by the Cormack-Lehane classification. The preanesthesia and anesthesia data of 1677 patients who had undergone general anesthesia at a single center were collected. The data set was randomly stratified into a training set (80\%) and a test set (20\%), with equal distribution of difficulty laryngoscopy. The training data sets were trained with five algorithms (logistic regression, multilayer perceptron, random forest, extreme gradient boosting, and light gradient boosting machine). The prediction models were validated through a test set. The model’s performance using random forest was best (area under receiver operating characteristic curve = 0.79 [95\% confidence interval: 0.72–0.86], area under precision-recall curve = 0.32 [95\% confidence interval: 0.27–0.37]). Machine learning can predict difficult laryngoscopy through a combination of several predictors including neck circumference and thyromental height. The performance of the model can be improved with more data, a new variable and combination of models.}}, 
pages = {125}, 
number = {1}, 
volume = {21}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/BMC%20Anesthesiology/Kim-2021-Development%20and%20validation%20of%20a%20difficult%20laryngoscopy%20prediction%20model%20using%20machine%20learning%20of%20neck%20circumference%20and%20thyromental%20height.pdf}
}
@article{10.35940/ijeat.a1612.109119, 
year = {2019}, 
title = {{Efficient Detection of Brachial Plexus in Ultrasound Images using Machine Learning Algorithms}}, 
author = {Sharma, Deepak and Kumar, Lalit}, 
journal = {International Journal of Engineering and Advanced Technology}, 
doi = {10.35940/ijeat.a1612.109119}, 
abstract = {{Humans can identify objects from an image. Only better knowledge can help to identify specific objects from the field in which we are working. The present work aims at detection of collection of nerves called the Brachial Plexus in ultrasound images. Ultrasound Images has been used for its low prices and low risks but they poses some challenges to detecting the Brachial Plexus in ultrasound images.}}, 
pages = {4195--4202}, 
number = {1}, 
volume = {9}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/International%20Journal%20of%20Engineering%20and%20Advanced%20Technology/Sharma-2019-Efficient%20Detection%20of%20Brachial%20Plexus%20in%20Ultrasound%20Images%20using%20Machine%20Learning%20Algorithms.pdf}
}
@article{10.1109/icispc.2019.8935668, 
year = {2019}, 
title = {{Deep Learning for Semantic Segmentation of Brachial Plexus Nervesin Ultrasound Images Using U-Net and M-Net}}, 
author = {Abraham, Nabila and Illanko, Kandasamy and Khan, Naimul and Androutsos, Dimitri}, 
journal = {2019 3rd International Conference on Imaging, Signal Processing and Communication (ICISPC)}, 
doi = {10.1109/icispc.2019.8935668}, 
abstract = {{Results of deep learning methods applied to semantic segmentation of ultrasound images in order to detect brachial plexus nerve sites are presented in this paper. Ultrasound Guided Regional Anesthesia (UGRA) can be used in pain management to reduce the risk of block failure and nerve trauma complications. Many years of experience is required on the part of the anesthesiologist to manually identify a particular nerve structure from an ultrasound image which is often contaminated with speckle noise and motion artifacts. Automating the process of identifying the nerve site using image segmentation would benefit the development of UGRA practices and reduce the risks associated with regional anesthesia treatments. In this paper edge filtering methods and two variations of the convolutional neural network, U-Net and M-Net architectures are used to segment ultrasound images automatically. Modified M-Net with average pooling is observed to produce the best results.}}, 
pages = {85--89}, 
volume = {00}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/2019%203rd%20International%20Conference%20on%20Imaging,%20Signal%20Processing%20and%20Communication%20(ICISPC)/Abraham-2019-Deep%20Learning%20for%20Semantic%20Segmentation%20of%20Brachial%20Plexus%20Nervesin%20Ultrasound%20Images%20Using%20U-Net%20and%20M-Net.pdf}
}
@article{10.1097/aln.0000000000002960, 
year = {2020}, 
title = {{Artificial Intelligence in Anesthesiology}}, 
author = {Hashimoto, Daniel A and Witkowski, Elan and Gao, Lei and Meireles, Ozanan and Rosman, Guy}, 
journal = {Anesthesiology}, 
issn = {0003-3022}, 
doi = {10.1097/aln.0000000000002960}, 
pmid = {31939856}, 
abstract = {{Abstract Artificial intelligence has been advancing in fields including anesthesiology. This scoping review of the intersection of artificial intelligence and anesthesia research identified and summarized six themes of applications of artificial intelligence in anesthesiology: (1) depth of anesthesia monitoring, (2) control of anesthesia, (3) event and risk prediction, (4) ultrasound guidance, (5) pain management, and (6) operating room logistics. Based on papers identified in the review, several topics within artificial intelligence were described and summarized: (1) machine learning (including supervised, unsupervised, and reinforcement learning), (2) techniques in artificial intelligence (e.g., classical machine learning, neural networks and deep learning, Bayesian methods), and (3) major applied fields in artificial intelligence. The implications of artificial intelligence for the practicing anesthesiologist are discussed as are its limitations and the role of clinicians in further developing artificial intelligence for use in clinical care. Artificial intelligence has the potential to impact the practice of anesthesiology in aspects ranging from perioperative support to critical care delivery to outpatient pain management.}}, 
pages = {379--394}, 
number = {2}, 
volume = {132}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Anesthesiology/Hashimoto-2020-Artificial%20Intelligence%20in%20Anesthesiology.pdf}
}
@article{10.1111/anae.15274, 
year = {2021}, 
title = {{The use of artificial intelligence and robotics in regional anaesthesia}}, 
author = {McKendrick, M. and Yang, S. and McLeod, G. A.}, 
journal = {Anaesthesia}, 
issn = {0003-2409}, 
doi = {10.1111/anae.15274}, 
pmid = {33426667}, 
abstract = {{The current fourth industrial revolution is a distinct technological era characterised by the blurring of physics, computing and biology. The driver of change is data, powered by artificial intelligence. The UK National Health Service Topol Report embraced this digital revolution and emphasised the importance of artificial intelligence to the health service. Application of artificial intelligence within regional anaesthesia, however, remains limited. An example of the use of a convoluted neural network applied to visual detection of nerves on ultrasound images is described. New technologies that may impact on regional anaesthesia include robotics and artificial sensing. Robotics in anaesthesia falls into three categories. The first, used commonly, is pharmaceutical, typified by target‐controlled anaesthesia using electroencephalography within a feedback loop. Other types include mechanical robots that provide precision and dexterity better than humans, and cognitive robots that act as decision support systems. It is likely that the latter technology will expand considerably over the next decades and provide an autopilot for anaesthesia. Technical robotics will focus on the development of accurate sensors for training that incorporate visual and motion metrics. These will be incorporated into augmented reality and visual reality environments that will provide training at home or the office on life‐like simulators. Real‐time feedback will be offered that stimulates and rewards performance. In discussing the scope, applications, limitations and barriers to adoption of these technologies, we aimed to stimulate discussion towards a framework for the optimal application of current and emerging technologies in regional anaesthesia.}}, 
pages = {171--181}, 
number = {S1}, 
volume = {76}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Anaesthesia/McKendrick-2021-The%20use%20of%20artificial%20intelligence%20and%20robotics%20in%20regional%20anaesthesia.pdf}
}
@article{10.1002/jum.15270, 
year = {2020}, 
title = {{Creation and Testing of a Deep Learning Algorithm to Automatically Identify and Label Vessels, Nerves, Tendons, and Bones on Cross‐sectional Point‐of‐Care Ultrasound Scans for Peripheral Intravenous Catheter Placement by Novices}}, 
author = {Blaivas, Michael and Arntfield, Robert and White, Matthew}, 
journal = {Journal of Ultrasound in Medicine}, 
issn = {0278-4297}, 
doi = {10.1002/jum.15270}, 
pmid = {32181922}, 
abstract = {{We sought to create a deep learning (DL) algorithm to identify vessels, bones, nerves, and tendons on transverse upper extremity (UE) ultrasound (US) images to enable providers new to US‐guided peripheral vascular access to identify anatomy. We used publicly available DL architecture (YOLOv3) and deidentified transverse US videos of the UE for algorithm development. Vessels, bones, tendons, and nerves were labeled with bounding boxes. A total of 203,966 images were generated from videos, with corresponding label box coordinates in a YOLOv3 format. Training accuracy, losses, and learning curves were tracked. As a final real‐world test, 50 randomly selected images from unrelated UE US videos were used to test the DL algorithm. Four different versions of the YOLOv3 algorithm were tested with varied amounts of training and sensitivity settings. The same 50 images were labeled by 2 blinded point‐of‐care ultrasound (POCUS) experts. The area under the curve (AUC) was calculated for the DL algorithm and POCUS expert performance. The algorithm outperformed POCUS experts in detection of all structures in the UE, with an AUC of 0.78 versus 0.69 and 0.71, respectively. When considering vessels, only one of the POCUS experts attained an AUC of 0.85, just ahead of the DL algorithm, with an AUC of 0.83. Our DL algorithm proved accurate at identifying 4 common structures on cross‐sectional US imaging of the UE, which would allow novice POCUS providers to more confidently and accurately target vessels for cannulation, avoiding other structures. Overall, the algorithm outperformed 2 blinded POCUS experts.}}, 
pages = {1721--1727}, 
number = {9}, 
volume = {39}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Journal%20of%20Ultrasound%20in%20Medicine/Blaivas-2020-Creation%20and%20Testing%20of%20a%20Deep%20Learning%20Algorithm%20to%20Automatically%20Identify%20and%20Label%20Vessels,%20Nerves,%20Tendons,%20and%20Bones%20on%20Cross‐sectional%20Point‐of‐Care%20Ultrasound%20Scans%20for%20Peripheral%20Intravenous%20Catheter%20Placement%20by%20Novices.pdf}
}
@article{10.1213/ANE.0000000000004897, 
year = {2020}, 
title = {{The Performance of an Artificial Neural Network Model in Predicting the Early Distribution Kinetics of Propofol in Morbidly Obese and Lean Subjects}}, 
author = {Ingrande, Jerry and Gabriel, Rodney A and McAuley, Julian and Krasinska, Karolina and Chien, Allis and Lemmens, Hendrikus J M}, 
journal = {Anesthesia \& Analgesia}, 
issn = {0003-2999}, 
doi = {10.1213/ANE.0000000000004897}, 
pmid = {32483038}, 
abstract = {{Induction of anesthesia is a phase characterized by rapid changes in both drug concentration and drug effect. Conventional mammillary compartmental models are limited in their ability to accurately describe the early drug distribution kinetics. Recirculatory models have been used to account for intravascular mixing after drug administration. However, these models themselves may be prone to misspecification. Artificial neural networks offer an advantage in that they are flexible and not limited to a specific structure and, therefore, may be superior in modeling complex nonlinear systems. They have been used successfully in the past to model steady-state or near steady-state kinetics, but never have they been used to model induction-phase kinetics using a high-resolution pharmacokinetic dataset. This study is the first to use an artificial neural network to model early- and late-phase kinetics of a drug.}}, 
number = {5}, 
volume = {131}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Anesthesia%20&%20Analgesia/Ingrande-2020-The%20Performance%20of%20an%20Artificial%20Neural%20Network%20Model%20in%20Predicting%20the%20Early%20Distribution%20Kinetics%20of%20Propofol%20in%20Morbidly%20Obese%20and%20Lean%20Subjects.pdf}
}
@article{10.1016/j.jclinane.2021.110219, 
year = {2021}, 
title = {{Artificial intelligence in anesthesiology: What are the missing pieces?}}, 
author = {Goldstein, Joseph C. and Goldstein, Heidi V.}, 
journal = {Journal of Clinical Anesthesia}, 
issn = {0952-8180}, 
doi = {10.1016/j.jclinane.2021.110219}, 
pages = {110219}, 
volume = {71}
}
@article{10.1109/embc.2015.7319045, 
year = {2015}, 
title = {{Automatic Segmentation of Nerve Structures in Ultrasound Images Using Graph Cuts and Gaussian Processes}}, 
author = {González, Julián Gil and Alvarez, Mauricio A. and Orozco, Alvaro A.}, 
journal = {2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
issn = {1557-170X}, 
doi = {10.1109/embc.2015.7319045}, 
pmid = {26736945}, 
abstract = {{Peripheral Nerve Blocking (PNB), is a procedure used for performing regional anesthesia, that comprises the administration of anesthetic in the proximity of a nerve. Several techniques have been used with the purpose of locating nerve structures when the PNB procedure is performed: anatomical surface landmarks, elicitation of paresthesia, nerve stimulation and ultrasound imaging. Among those, ultrasound imaging has gained great attention because it is not invasive and offers an accurate location of the nerve and the structures around it. However, the segmentation of nerve structures in ultrasound images is a difficult task for the specialist, since such images are affected by echo perturbations and speckle noise. The development of systems for the automatic segmentation of nerve structures can aid the specialist for locating nerve structures accurately. In this paper we present a methodology for the automatic segmentation of nerve structures in ultrasound images. An initial step is carried out using Graph Cut segmentation in order to generate regions of interest; we then use machine learning techniques with the aim of segmenting the nerve structure; here, a specific non-linear Wavelet transform is used for the feature extraction stage, and Gaussian processes for the classification step. The methodology performance is measured in terms of accuracy and the dice coefficient. Results show that the implemented methodology can be used for automatically segmenting nerve structures.}}, 
pages = {3089--3092}, 
volume = {2015}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/2015%2037th%20Annual%20International%20Conference%20of%20the%20IEEE%20Engineering%20in%20Medicine%20and%20Biology%20Society%20(EMBC)/González-2015-Automatic%20Segmentation%20of%20Nerve%20Structures%20in%20Ultrasound%20Images%20Using%20Graph%20Cuts%20and%20Gaussian%20Processes.pdf}
}
@article{10.1186/s12871-021-01331-8, 
year = {2021}, 
title = {{A prediction model using machine-learning algorithm for assessing intrathecal hyperbaric bupivacaine dose during cesarean section}}, 
author = {Wei, Chang-na and Wang, Li-ying and Chang, Xiang-yang and Zhou, Qing-he}, 
journal = {BMC Anesthesiology}, 
doi = {10.1186/s12871-021-01331-8}, 
pmid = {33853548}, 
abstract = {{The intrathecal hyperbaric bupivacaine dosage for cesarean section is difficult to predetermine. This study aimed to develop a decision-support model using a machine-learning algorithm for assessing intrathecal hyperbaric bupivacaine dose based on physical variables during cesarean section. Term parturients presenting for elective cesarean section under spinal anaesthesia were enrolled. Spinal anesthesia was performed at the L3/4 interspace with 0.5\% hyperbaric bupivacaine at dosages determined by the anesthesiologist. A spinal spread level between T4-T6 was considered the appropriate block level. We used a machine-learning algorithm to identify relevant parameters. The dataset was split into derivation (80\%) and validation (20\%) cohorts. A decision-support model was developed for obtaining the regression equation between optimized intrathecal 0.5\% hyperbaric bupivacaine volume and physical variables. A total of 684 parturients were included, of whom 516 (75.44\%) and 168 (24.56\%) had block levels between T4 and T6, and less than T6 or higher than T4, respectively. The appropriate block level rate was 75.44\%, with the mean bupivacaine volume [1.965, 95\%CI (1.945,1.984)]ml. In lasso regression, based on the principle of predicting a reasonable dose of intrathecal bupivacaine with fewer physical variables, the model is “Y=0.5922+ 0.055117* X1-0.017599*X2” (Y: bupivacaine volume; X1: vertebral column length; X2: abdominal girth), with λ 0.055, MSE 0.0087, and R2 0.807. After applying a machine-learning algorithm, we developed a decision model with R2 0.8070 and MSE due to error 0.0087 using abdominal girth and vertebral column length for predicting the optimized intrathecal 0.5\% hyperbaric bupivacaine dosage during term cesarean sections.}}, 
pages = {116}, 
number = {1}, 
volume = {21}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/BMC%20Anesthesiology/Wei-2021-A%20prediction%20model%20using%20machine-learning%20algorithm%20for%20assessing%20intrathecal%20hyperbaric%20bupivacaine%20dose%20during%20cesarean%20section.pdf}
}
@article{10.21037/29596, 
year = {2019}, 
title = {{Applying deep learning in recognizing the femoral nerve block region on ultrasound images}}, 
author = {Huang, Chanyan and Zhou, Ying and Tan, Wulin and Qiu, Zeting and Zhou, Huaqiang and Song, Yiyan and Zhao, Yue and Gao, Shaowei}, 
journal = {Annals of Translational Medicine}, 
issn = {2305-5847}, 
doi = {10.21037/29596}, 
pmid = {31700889}, 
abstract = {{Background: Identifying the nerve block region is important for the less experienced operators who are not skilled in ultrasound technology. Therefore, we constructed and shared a dataset of ultrasonic images to explore a method to identify the femoral nerve block region. Methods: Ultrasound images of femoral nerve block were retrospectively collected and marked to establish the dataset. The U-net framework was used for training data and output segmentation of region of interest. The performance of the model was evaluated by Intersection over Union and accuracy. Then the predicted masks were highlighted on the original image to give an intuitive evaluation. Finally, cross validation was used for the whole data to test the robust of the results. Results: We selected 562 ultrasound images as the whole dataset. The training set intersection over union (IoU) was 0.713, the development set IoU is 0.633 and the test set IoU is 0.638. For the single image, the median and upper/lower quartiles of IoU were 0.722 (0.647–0.789), 0.653 (0.586–0.703), 0.644 (0.555–0.735) for the training set, development set and test set respectively. The segmentation accuracy of the test set was 83.9\%. For 10-fold cross validation, the median and quartiles of the 10-iteration sum IoUs was 0.656 (0.628–0.672); for accuracy, they were 88.4\% (82.1–90.7\%). Conclusions: We provided a dataset and trained a model for femoral-nerve region segmentation with U-net, obtaining a satisfactory performance. This technique may have potential clinical application.}}, 
pages = {453--453}, 
number = {18}, 
volume = {7}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Annals%20of%20Translational%20Medicine/Huang-2019-Applying%20deep%20learning%20in%20recognizing%20the%20femoral%20nerve%20block%20region%20on%20ultrasound%20images.pdf}
}
@article{10.1016/j.eswa.2016.05.002, 
year = {2016}, 
title = {{Assistive system based on nerve detection and needle navigation in ultrasound images for regional anesthesia}}, 
author = {Hadjerci, Oussama and Hafiane, Adel and Morette, Nicolas and Novales, Cyril and Vieyres, Pierre and Delbos, Alain}, 
journal = {Expert Systems with Applications}, 
issn = {0957-4174}, 
doi = {10.1016/j.eswa.2016.05.002}, 
abstract = {{The development of Ultrasound-Guided Regional Anesthesia (UGRA) is of great help to practitioners of regional anesthesia as it enables real time visualization of the needle, the targeted nerve, and different anatomic structures. However, the clinician has to perform a complex hand coordination to keep the needle, the nerve and some key regions visible in the ultrasound image plane. Daily clinical practice therefore requires a high degree of training and practical skill to identify the nerve block and steer the needle to it. There are two critical steps in UGRA: the recognition of anatomical structures and steering the needle to the target region. An intelligent system, with the ability to identify the regions of interest and to provide the needle insertion trajectory in ultrasound images, can significantly improve UGRA practice and generalize it to medical facilities that lack practitioners. It would also make the UGRA procedure safer (i.e., reducing the risk of nerve trauma). This work presents the first fully automatic system for the detection of regions of interest and generation of the needle trajectory for UGRA. Several problems were addressed, in two stages. The first one consisted in the automatic localization and segmentation of the nerve (target) and arteries (obstacles) in ultrasound images. A new method based on a machine learning algorithm with a multi-model classification process using a sliding window for localization, then an active contour was applied to delineate the localized regions. In the second stage, an algorithm for path planning was also developed to obtain the optimal trajectory for needle insertion based on the result of the first stage (target and obstacle detection). To check the effectiveness of the proposed system, firstly, experiments were performed over individual modules of the detection framework. Secondly, a comparison between the overall framework and the existing method was performed. Two data-sets were acquired in real conditions at different times to prove the robustness of our method. The first data-set contained eight patients and the second data-set, acquired one year later, contained five patients. Experimental results demonstrate the robustness of the proposed scheme and the feasibility of such an assistive system.}}, 
pages = {64--77}, 
volume = {61}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/Expert%20Systems%20with%20Applications/Hadjerci-2016-Assistive%20system%20based%20on%20nerve%20detection%20and%20needle%20navigation%20in%20ultrasound%20images%20for%20regional%20anesthesia.pdf}
}
@article{10.1016/j.bja.2020.06.049, 
year = {2020}, 
title = {{Artificial intelligence: a new frontier for anaesthesiology training}}, 
author = {Arora, Anmol}, 
journal = {British Journal of Anaesthesia}, 
issn = {0007-0912}, 
doi = {10.1016/j.bja.2020.06.049}, 
local-url = {file://localhost/Users/rob/Documents/Papers%20Library/British%20Journal%20of%20Anaesthesia/Arora-2020-Artificial%20intelligence-%20a%20new%20frontier%20for%20anaesthesiology%20training.pdf}
}