title: What is deep learning?
description: Deep learning is an AI technique that is able to learn complex patterns in large data sets.
groups: rtc
picture: projects/ai_for_health.png

### Deep neural networks

The concept of artificial neural networks (ANN) has existed for several decades. ANNs are loosely inspired by the manner in which the human brain processes information through a complex network of interconnected neuronal cells. ANNs consist of multiple processing units also called neurons, just as in the central nervous system, which are stacked in numerous layers. The units of an ANN layer are connected to all units of the preceding and following layer. The first layer of neurons processes an input signal and produces a numerical activation as output. The neurons in the deeper layers of the network, also called hidden neurons, process the weighted inputs received from the connections with the previous layer. The final layer consists of output neurons which convey the information that has been learned by the model for a given input. 

A neuron computes the sum of the product of each input connection and its associated weight, followed by a given activation function to produce its output. This can be given as the following equation:

<img src="https://latex.codecogs.com/svg.latex?\large&space;Y&space;=&space;f\left&space;(\sum_{i}^{n}&space;w_{i}x_{i}\right&space;)," title="\large Y = f\left (\sum_{i}^{n} w_{i}x_{i}\right )," />

where ***x*** and ***w*** are the input and weight for a given connection ***i*** and the sum is taken over ***n*** connections before computing the output ***Y*** through the activation function ***f***. The activation function is used to map the sum of weighted inputs of a neuron to a specific range of values, depending on which activation function is chosen. Commonly used activation functions include the *tanh* function, sigmoid function and rectified linear unit (ReLU). Once the activation function has been applied as shown in the equation above, the output of that neuron is used as input for neurons in the subsequent layer of the model.

Models can be trained in a supervised manner for a certain task. That is, the model learns to associate raw input data with a certain outcome. Given a specific input and reference standard as outcome, the weights corresponding to all connections between neurons in the model are adjusted so that the model produces an output that best resembles the reference standard. This manner of training is achieved by the minimization of a loss function using some form

### Convolutional neural networks

Convolutional neural networks (CNN) are a specific type of deep neural network designed to process spatial information, such as in image processing tasks. Like ANNs, CNNs consist of multiple interconnected layers that associate input information with a specific output. However, in CNNs one or multiple layers consist of convolutional operations that process spatial information through local matrix multiplications of given kernel dimensions and typically with a square shape. Therefore, the neurons in ANNs are connected to all neurons in the previous and next layer, where CNNs incorporate local information that lies within their so-called receptive field and pass this on to the next layer in the model. In this manner, multiple filters that operate in parallel produce feature maps at each hidden layer in the model. As the depth of the model and the number of hidden layers increases, the abstractness and complexity of the extracted features and the feature maps that are produced also increase.

Generally, CNNs also incorporate other specific layers in the model architecture, such as pooling operations and fully connected layers. As with convolutional operations, pooling operations process information in a local region defined by a kernel size. The pooling calculates some form of a summary statistic for the local region, commonly a 2x2 square, such as the local average or maximum. The kernel is passed over the input with a stride equal to its dimensions, producing a feature map that is half the size of the input. Therefore, such operations improve the computational efficiency of CNNs by reducing the size of intermediate feature maps that are produced by hidden layers. Furthermore, they introduce a slight translational invariance to the model, making it more robust to variations of the input data. Fully connected layers, also called dense or densely connected layers, are connected to all activations of the preceding hidden layer. They incorporate all compacted feature representations produced as a result of the input passing through the extent of the network. The layer produces a simplified vector of features that is used by the model to distinguish between classification outputs. A schematic representation of an ANN and CNN is shown in the figure below.

<figure class="figure my-4">
  <img data-src="{{ IMGURL }}/images/projects/CNN.png" class="figure-img img-fluid lazyload rounded" alt="Convolutional neural network.">
  <figcaption class="figure-caption">Schematic representations of artificial neural network (ANN) and convolutional neural network (CNN). In an ANN, input information is processed by fully interconnected neurons in hidden layers to produce an output (top). CNNs use multiple layers of convolutional and pooling operations that process local information to extract increasingly complex feature representations of the input data (bottom).</figcaption>
</figure>

The use of CNNs has rapidly increased in the past decade. The fast technological developments of the 21<sup>st</sup> century have enabled the creation of high-performance computers and graphics processing units (GPU). GPUs are hardware originally designed for image processing tasks such as displaying high-definition video or rendering 3D games. However, their structure consists of thousands of specialized cores, many more than on conventional central processing units (CPU), making them especially adept at processing matrices. This makes them highly suitable for the many memory-intensive matrix multiplications necessary to train CNNs. Aside from enough computational power, the training of CNNs also requires a large amount of input data. To adequately learn the weights of the model to solve a specific problem, the input dataset must be large enough to encompass the variance that can generally be found. Therefore, the dataset used to train a model must be sufficiently representative of the problem to create a method that is capable of broad generalization. The introduction of large, publicly-available datasets was another important catalyst for the use of CNNs in computer vision. 

Since 2010, the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) has been hosted annually. This challenge provides a large dataset of manually labeled images for teams to develop their algorithms. The goal of the challenge is to develop an algorithm that achieves the lowest error rate for visual recognition tasks where images must be classified into one of a thousand possible classes. In 2012, the winning submission employed a CNN using a GPU for training the model. The error rate achieved was approximately 16%, which at the time was 10% lower than the runner-up. In the following years the error rate decreased further to a few percent due to the extensive use of CNNs. As of 2019, the publication describing the method has been cited over 35.000 times. This landmark challenge victory is generally considered the cause of a deep learning revolution that saw the widespread implementation of CNNs across various domains, including medical image analysis.

The use of CNNs for medical image analysis has progressed in parallel to their use in other fields. The number of publications that employ some form of deep learning in the field has grown exponentially in the last decade. The use of neural networks has become the norm for problems ranging from segmentation and quantification to object detection and classification. Generally, the development of high-performance CNNs requires three essential components: computational power, a large amount of data and a high-quality reference standard. In medical image analysis, this is an obstacle, as datasets are often limited and the creation of manual, expertly-annotated reference standards is time-consuming and costly. Nevertheless, CNNs have shown to rival expert human performance in various fields. 
