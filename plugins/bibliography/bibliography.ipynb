{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import latexcodec\n",
    "import codecs\n",
    "import glob\n",
    "import os \n",
    "\n",
    "def save_dict2json(json_path, dict_md5):\n",
    "    with open(json_path, 'w') as fp:\n",
    "        json.dump(dict_md5, fp)\n",
    "\n",
    "def load_json2dict(json_path):\n",
    "    if os.path.exists(json_path):\n",
    "        json_file = open(json_path)\n",
    "        json_data = json.load(json_file)\n",
    "    else:\n",
    "        json_data = None\n",
    "    return json_data\n",
    "\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "\n",
    "def authors_to_string(names, bib_key):\n",
    "    string_authors = ''\n",
    "    d = ', '\n",
    "    for idx, name in enumerate(names):\n",
    "        first, von, last, jr = name\n",
    "        if first:\n",
    "            first = first[0] + '.'\n",
    "#         if first:\n",
    "#             first = ''.join([f.strip('.').strip(',')[0].capitalize()+'.' for f in first.strip().replace('  ', ' ').split(' ')])\n",
    "#         if '.' in von:\n",
    "#             first = ''.join([first, *von.upper().split(' ')])\n",
    "#             von = ''\n",
    "#         if last:\n",
    "#             last = '-'.join([l.capitalize() for l in last.strip().split('-')])\n",
    "        if idx == len(names)-2:\n",
    "            d = ' and '\n",
    "        if idx == len(names)-1:\n",
    "            d = ''\n",
    "        string_authors += ' '.join(part for part in [first, von, last, jr] if part) + d\n",
    "    return string_authors\n",
    "\n",
    "# pasre bib file\n",
    "def get_blocks(content, start_character='@', delim=('{','}')):\n",
    "    '''\n",
    "    returns all blocks (entries enclosed by the specified delimiters)\n",
    "    start_character will look backwards from the start of the block for this character\n",
    "    the result will be a tuple of two strings: from start character to start of the block, and the block content\n",
    "    '''\n",
    "    blocks = []\n",
    "    \n",
    "    delim_start, delim_end = delim\n",
    "    delimiter_stack = []\n",
    "    for i, c in enumerate(content):\n",
    "        if c == '{':\n",
    "            delimiter_stack.append(i)\n",
    "        elif c == '}' and delimiter_stack:\n",
    "            start = delimiter_stack.pop()\n",
    "            if len(delimiter_stack)==0:\n",
    "                start_index = content.rfind(start_character, 0, start)\n",
    "                blocks.append((content[start_index: start], content[start + 1: i]))\n",
    "    return blocks\n",
    "\n",
    "assert [x for x in get_blocks('abc = {test}, bac = {test2}', 'a')] == [('abc = ', 'test'), ('ac = ', 'test2')]\n",
    "\n",
    "\n",
    "def decode_name(name):\n",
    "    parsed_name = []\n",
    "    for name_part in name:\n",
    "        name_part = name_part.strip()\n",
    "        if '\\\\' in name_part:\n",
    "            name_part = codecs.decode(name_part, 'ulatex')\n",
    "        parsed_name.append(name_part)\n",
    "    return parsed_name\n",
    "\n",
    "\n",
    "def parse_name(name):\n",
    "    '''\n",
    "    assumes this format:\n",
    "    https://tex.stackexchange.com/questions/557/how-should-i-type-author-names-in-a-bib-file\n",
    "    returns a tuple (first, von, last, jr)\n",
    "    '''\n",
    "    parts = name.strip(',').split(',')\n",
    "    \n",
    "    # \"First von Last\"\n",
    "    if len(parts)==1:\n",
    "        s, e = (name.index(' '), name.rfind(' ')) if ' ' in name else (0, 0)\n",
    "        first = name[:s]\n",
    "        von = name[s:e]\n",
    "        last = name[e:]\n",
    "        jr = ''\n",
    "        \n",
    "    # \"von Last, First\"\n",
    "    elif len(parts)==2: \n",
    "        first = parts[1]\n",
    "        e = parts[0].rfind(' ') if ' ' in parts[0] else 0\n",
    "        von = parts[0][:e]\n",
    "        last = parts[0][e:]\n",
    "        jr = ''\n",
    "        \n",
    "    # \"von Last, Jr, First\"\n",
    "    elif len(parts)==3: \n",
    "        first = parts[2]\n",
    "        e = parts[0].rfind(' ') if ' ' in parts[0] else 0\n",
    "        von = parts[0][:e]\n",
    "        last = parts[0][e:]\n",
    "        jr = parts[1]\n",
    "        \n",
    "    else:\n",
    "        print('warning! bibtex format error in name \"{}\"'.format(''.join(name)))\n",
    "        first, von, last, jr = '', '', name, ''  \n",
    "    \n",
    "    nfirst = ''\n",
    "    for f in first.strip().split('.'):\n",
    "        f = f.strip()\n",
    "        f = f.capitalize()\n",
    "        if len(f) == 1:\n",
    "            f += '.'    \n",
    "        nfirst = ' '.join([nfirst, f])\n",
    "    \n",
    "    #post process von to second names\n",
    "    nvon = ''\n",
    "    for v in von.strip().split():\n",
    "        v = v.strip()\n",
    "        if v[0].isupper():\n",
    "            nfirst = ' '.join([nfirst, v])\n",
    "        else:\n",
    "            nvon = ' '.join([nvon, v])\n",
    "    \n",
    "    #post process first and second names\n",
    "    nfirst2 = ''\n",
    "    for f in nfirst.strip().split():\n",
    "        f = f.strip()\n",
    "        f = f.capitalize()\n",
    "        if len(f) == 1:\n",
    "            f += '.'    \n",
    "        nfirst2 = ' '.join([nfirst2, f]) \n",
    "        \n",
    "    last = '-'.join(last.strip().split())\n",
    "        \n",
    "    return decode_name((nfirst2, nvon, last, jr))\n",
    "\n",
    "\n",
    "assert parse_name('Bart Liefers') == ['Bart', '', 'Liefers', '']\n",
    "assert parse_name('Bart von Liefers') == ['Bart', 'von', 'Liefers', '']\n",
    "assert parse_name('Liefers, Bart') == ['Bart', '', 'Liefers', '']\n",
    "assert parse_name('von Liefers, Bart') == ['Bart', 'von', 'Liefers', '']\n",
    "# assert parse_name('von Liefers, Jr, Bart') == ['Bart', 'von', 'Liefers', 'Jr']\n",
    "\n",
    "\n",
    "def parse_block_content(bib_item_text):\n",
    "    bib_item = {}\n",
    "    \n",
    "    # split lines and remove ',' at the end\n",
    "    bib_item_text = bib_item_text.replace('\\r', '\\n').replace('\\r\\n', '\\n')\n",
    "    lines  = bib_item_text.split(',\\n')\n",
    "    \n",
    "    # bib key\n",
    "    bib_key = lines[0].lower()\n",
    "    \n",
    "    # parse lines\n",
    "    for line in lines[1:]:\n",
    "        \n",
    "        # check if line is parseable\n",
    "        if '=' not in line or line == '':\n",
    "            continue \n",
    "            \n",
    "        # split by tags notated by '='   \n",
    "        key, value = line.split('=', 1)\n",
    "\n",
    "        # strip unneccary symbols\n",
    "        key = key.lower().strip()\n",
    "        value = value.strip().strip('{').strip('}')\n",
    "                    \n",
    "        # set bib_item\n",
    "        bib_item[key] = value\n",
    "    \n",
    "    return bib_key, bib_item\n",
    " \n",
    "def single_author(author_string):\n",
    "    splits = author_string.split(',')\n",
    "    splits = [s.strip() for s in splits]\n",
    "    return len(splits) == 2 and not(' ' in splits[0] and ' ' in splits[1])\n",
    "\n",
    "def split_authors(author_string):\n",
    "    authors = []\n",
    "    if 'and' in author_string.lower() or single_author(author_string):\n",
    "        authors = author_string.replace('AND', 'and').split(' and ')\n",
    "    else:\n",
    "        authors = author_string.split(',')\n",
    "    authors = [a.strip().replace('{', '').replace('}', '') for a in authors]\n",
    "    return authors\n",
    "\n",
    "def read_bibtex_file(filename):\n",
    "    bib_items = {}\n",
    "    string_rules = {}\n",
    "    with open(filename, 'rb') as f:\n",
    "        content = f.read().decode('utf-8-sig')\n",
    "\n",
    "    for block in get_blocks(content):\n",
    "        block_name, block_content = block\n",
    "        if block_name == '@Comment':\n",
    "            continue\n",
    "        elif block_name == '@String':\n",
    "            k, v = [x.strip() for x in block_content.split('=')]\n",
    "            string_rules[k] = v  \n",
    "        else: #bib item text\n",
    "\n",
    "            # parse bib item text\n",
    "            bib_key, bib_item = parse_block_content(block_content)\n",
    "            \n",
    "            # update type\n",
    "            bib_item['type'] = block_name.strip('@').lower()\n",
    "            \n",
    "            # update journal name\n",
    "            if 'journal' in bib_item:\n",
    "                bib_item['journal'] = string_rules[bib_item['journal']].strip('_').replace('_', ' ') if bib_item['journal'] in string_rules else bib_item['journal']\n",
    "\n",
    "            bib_item['author'] = list(map(parse_name, split_authors(bib_item['author'])))\n",
    "            bib_item['authors'] = authors_to_string(bib_item['author'], bib_key)\n",
    "\n",
    "\n",
    "            if 'copromotor' in bib_item:\n",
    "                try:\n",
    "                    bib_item['author'] += list(map(parse_name, split_authors(bib_item['copromotor'])))\n",
    "                except:\n",
    "                    print('bib_key cp', bib_key)\n",
    "           \n",
    "            if 'promotor' in bib_item:\n",
    "                try:\n",
    "                    bib_item['author'] += list(map(parse_name, split_authors(bib_item['promotor'])))\n",
    "                except:\n",
    "                    print('bib_key p', bib_key)\n",
    "#             if 'optnote' in bib_item and 'diag' in bib_item['optnote'].lower():\n",
    "\n",
    "            bib_items[bib_key.lower()] = bib_item\n",
    "    return bib_items\n",
    "\n",
    "\n",
    "# authors\n",
    "def get_list_researchers(members_path):\n",
    "    list_researchers = []\n",
    "    for people_md_path in glob.glob(members_path + '/*.md'):\n",
    "        with open(people_md_path) as fp:\n",
    "            # parse md file\n",
    "            tags = {line.split(':')[0]:line.split(':')[1].strip().lower().split() for line in (fp) if len(line.split(':')) > 1}\n",
    "\n",
    "            # get publication name\n",
    "            research_name = [n.lower() for n in tags['pub_name']] if 'pub_name' in tags else [n.lower() for n in tags['name']]\n",
    "\n",
    "        # append researches \n",
    "        list_researchers.append(research_name)    \n",
    "    return list_researchers\n",
    "\n",
    "\n",
    "# author publications\n",
    "def get_publications_by_author(bib_items, list_researchers, debug_args=None):\n",
    "    author_bibkeys = {}\n",
    "    debug=False\n",
    "    for bib_key, bib_item in bib_items.items():\n",
    "        authors = bib_item['author']\n",
    "        for researcher_name in list_researchers:\n",
    "            firstname = researcher_name[0]\n",
    "            lastnames = researcher_name[1:]\n",
    "            \n",
    "            if debug_args:\n",
    "                debug = True if bib_key == debug_args['bib_key'] and firstname == debug_args['firstname'] else False\n",
    "                \n",
    "            if len(lastnames) > 1:\n",
    "                # This fixes issue #10 for lastnames connected with a dash (-)\n",
    "                lastnames.append('-'.join(lastnames))\n",
    "            for author_pub in authors:\n",
    "                if match_author_publication(firstname, lastnames, author_pub, bib_key):\n",
    "                    author_bibkeys.setdefault('-'.join(researcher_name), []).append(bib_key)\n",
    "    return author_bibkeys\n",
    "\n",
    "\n",
    "def match_author_publication(firstname, lastnames, author, bib_key):\n",
    "    # This function selects authors with the same lastname and matches the first name.\n",
    "    # For instance, 'A. Patel' will always represent 'Ajay Patel' and not 'Anup Patel'.\n",
    "    # If the bib file contains 'A Patel' then, it will associate the bibentry to 'Ajay Patel'.\n",
    "    # If the bib file contains 'M F L Meijs' then, this script will not associate the bibentry to 'Midas Meijs'\n",
    "    #  because it will check for the existence of von and jr (F and L in the example)\n",
    "    author = [xname.replace('.', ' ').strip() for xname in author]\n",
    "    try:\n",
    "        first, von, last, jr = author\n",
    "    except:\n",
    "        print(author)\n",
    "    first = first.lower()\n",
    "    last = last.lower()\n",
    "    jr = jr.lower()\n",
    "    \n",
    "    # Additional variable that may help to avoid incorrect name matching #77\n",
    "    von_last = '-'.join([von, last])\n",
    "    von_last = von_last.replace(' ', '-').lower()\n",
    "\n",
    "    if last.lower() in lastnames:\n",
    "        # First match based on last name\n",
    "        if len(first) > 1 and first.lower() == firstname.lower() or len(jr) > 1 and jr.lower() in lastnames:\n",
    "            # Easy match, the first name is complete and matches up\n",
    "            return True\n",
    "        elif len(first) > 1 and ' ' in first:\n",
    "            # Incomplete match, some bib entries have authors as 'R Manniesing' instead of the full name\n",
    "            # or 'J A W M van der Laak' where firstname contains 'J A W M'\n",
    "            # or 'Jeroen AWM van der Laak' where firstname contains 'Jeroen A W M'\n",
    "            # This piece of code makes sure there is only one name and no spaces in between\n",
    "#             von = ' '.join(first.split(' ')[1:]) + ' ' + von\n",
    "            first = first.split(' ')[0].lower()\n",
    "            if first == firstname.lower():\n",
    "                return True\n",
    "            # if 'first' contains a single letter, it will continue\n",
    "\n",
    "        if len(first) == 1 and first[0].lower() == firstname[0].lower():\n",
    "            # If only one letter is provided as first name (incomplete in the bib entry).\n",
    "            # An additional variable stores the initial lastnames\n",
    "            initials_lastnames = [x[0].lower() for x in lastnames]\n",
    "            if (len(von) == 0 and len(jr) == 0):\n",
    "                # If there is no 'von' neither 'jr', then it is a match\n",
    "                return True\n",
    "            elif (len(jr) >= 1 and jr[0].lower() in initials_lastnames):\n",
    "                # If 'jr' contains something, it will have to be listed on 'initials_lastnames'\n",
    "                # to become a match\n",
    "                return True\n",
    "            elif (len(von.strip()) >= 1 and von.strip()[0].lower() in initials_lastnames):\n",
    "                # If 'von' contains something, it will have to be listed on 'initials_lastnames'\n",
    "                # to become a match\n",
    "                return True\n",
    "            elif '-' != von_last[0] and len(lastnames) >= 2 and lastnames[-1] in von_last:\n",
    "                # If none of the previous methods worked, an additional checkup is done.\n",
    "                # This is done only when having at least two last names.\n",
    "                # the last lastname should be in 'von_last'.\n",
    "                # For instance 'J A W M van der Laak' will become 'A-W-M-van-der-Laak', this matches up with 'van-der-laak'\n",
    "                return True\n",
    "        return False\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bart', 'von', 'Liefers', '']"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_name('Bart von Liefers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bib_items\n",
    "@timeit\n",
    "def run():\n",
    "    bib_items = read_bibtex_file('../../content/diag.bib')\n",
    "    list_researchers = get_list_researchers('../../content/pages/members/')  \n",
    "    author_bib_keys = get_publications_by_author(bib_items, list_researchers)\n",
    "    save_dict2json('/home/mart/bitems.json', bib_items)\n",
    "    save_dict2json('/home/mart/authorkeys.json', author_bib_keys)\n",
    "    return bib_items, author_bib_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'run'  4694.82 ms\n"
     ]
    }
   ],
   "source": [
    "bib_items, author_bib_keys = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessment of tumor buds in colorectal cancer. A large-scale international digital observer study\n",
      "J. Bokhorst, H. Dawson, A. Blank, I. Zlobec, A. Lugli, M. Vieth, R. Kirsch, M. Urbanowicz, S. Brockmoeller, J. Flejou, L. Rijstenberg, J. van der Laak, F. Ciompi and I. Nagtegaal\n",
      "Learning from sparsely annotated data for semantic segmentation in histopathology images\n",
      "J. Bokhorst, H. Pinckaers, P. van Zwam, I. Nagetgaal, J. van der Laak and F. Ciompi\n",
      "Automatic Detection of Tumor Budding in Colorectal Carcinoma with Deep Learning\n",
      "J. Bokhorst, L. Rijstenberg, D. Goudkade, I. Nagtegaal, J. van der Laak and F. Ciompi\n",
      "Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology.\n",
      "D. Tellez, G. Litjens, P. Bándi, W. Bulten, J. Bokhorst, F. Ciompi and J. van der Laak\n",
      "Assessment of individual tumor buds using keratin immunohistochemistry: moderate interobserver agreement suggests a role for machine learning\n",
      "J. Bokhorst, A. Blank, A. Lugli, I. Zlobec, H. Dawson, M. Vieth, L. Rijstenberg, S. Brockmoeller, M. Urbanowicz, J. Flejou, R. Kirsch, F. Ciompi, J. van der Laak and I. Nagtegaal\n"
     ]
    }
   ],
   "source": [
    "for bkey in author_bib_keys['john-melle-bokhorst']: \n",
    "    print(bib_items[bkey]['title'])\n",
    "    print(bib_items[bkey]['authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import latexcodec\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D. Abásolo, C. Gómez, J. Poza, M. García, C. Sánchez and M. López'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# author_bib_keys['clara-i-sánchez']\n",
    "codecs.decode(bib_items['abas05a']['authors'], \"ulatex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rijt18', 'swid18', 'swid19']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_bib_keys['zaneta-swiderska-chadaj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101544'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bib_items['tell19']['pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
